기존 프로젝트에 ElevenLabs API를 사용한 딥보이스(DeepVoice) 음성 변환 기능을 추가해주세요.

현재 상태:
사용자 목소리 녹음 기능은 이미 구현되어 있음
녹음된 오디오 데이터를 사용할 수 있는 상태

구현할 기능:
백엔드 API 엔드포인트 생성 (Node.js/Express):
POST /api/convert-voice

요청 데이터:
녹음된 오디오 파일 (이미 저장된 오디오)
선택된 문장 텍스트

응답 데이터:
변환된 음성 오디오 (Blob 또는 Base64)

주요 처리 흐름:
   1. 클라이언트에서 녹음된 오디오 + 선택한 문장 받기
   2. ElevenLabs API로 음성 클론 생성 요청
   3. 선택된 문장을 해당 목소리로 TTS 변환
   4. 변환된 오디오를 클라이언트에 반환
   5. 서버의 임시 파일 즉시 삭제

ElevenLabs API 통합:
환경변수 설정 (.env):

   ELEVENLABS_API_KEY=your_api_key_here
API 호출 구조:
javascript   // 1단계: Voice ID 생성 (녹음된 오디오로 커스텀 보이스 생성)
   const createVoice = async (audioFile, name) => {
     const formData = new FormData();
     formData.append('files', audioFile);
     formData.append('name', name);
     
     const response = await fetch('
https://api.elevenlabs.io/v1/voices/add
', {
       method: 'POST',
       headers: {
         'xi-api-key': process.env.ELEVENLABS_API_KEY
       },
       body: formData
     });
     
     const data = await response.json();
     return data.voice_id;
   };

   // 2단계: 생성된 Voice ID로 TTS 변환
   const textToSpeech = async (voiceId, text) => {
     const response = await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${voiceId}`, {
       method: 'POST',
       headers: {
         'xi-api-key': process.env.ELEVENLABS_API_KEY,
         'Content-Type': 'application/json'
       },
       body: JSON.stringify({
         text: text,
         model_id: 'eleven_monolingual_v1',
         voice_settings: {
           stability: 0.5,
           similarity_boost: 0.75
         }
       })
     });
     
     return await response.blob();
   };

   // 3단계: 사용 후 Voice ID 삭제 (개인정보 보호)
   const deleteVoice = async (voiceId) => {
     await fetch(`https://api.elevenlabs.io/v1/voices/${voiceId}`, {
       method: 'DELETE',
       headers: {
         'xi-api-key': process.env.ELEVENLABS_API_KEY
       }
     });
   };

     
     try {
       // 이미 녹음된 오디오 데이터 가져오기 (기존 변수명에 맞게 수정)
       const formData = new FormData();
       formData.append('audio', recordedAudioBlob); // 기존에 저장된 오디오 변수
       formData.append('text', selectedSentence);
       
       const response = await fetch('/api/convert-voice', {
         method: 'POST',
         body: formData
       });
       
       if (!response.ok) {
         throw new Error('변환 실패');
       }
       
       const audioBlob = await response.blob();
       convertedAudioUrl = URL.createObjectURL(audioBlob);
       
       // 재생 버튼 표시
       document.getElementById('loading').style.display = 'none';
       document.getElementById('playBtn').style.display = 'block';
       
     } catch (error) {
       alert('변환 중 오류가 발생했어요. 다시 시도해주세요!');
       console.error(error);
     } finally {
       document.getElementById('convertBtn').disabled = false;
       document.getElementById('loading').style.display = 'none';
     }
   });
   
   // 변환된 목소리 재생
   document.getElementById('playBtn').addEventListener('click', () => {
     if (convertedAudioUrl) {
       const audio = new Audio(convertedAudioUrl);
       
audio.play
();
     }
   });

백엔드 라우트 구현 (routes/deepvoice.js):

javascript   const express = require('express');
   const router = express.Router();
   const multer = require('multer');
   const fs = require('fs').promises;
   const fetch = require('node-fetch');
   const FormData = require('form-data');
   
   const upload = multer({ dest: 'temp/' });
   
   
router.post
('/convert-voice', u